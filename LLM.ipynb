{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71aab9a3-ce2b-48ec-a8d7-cfde06d543c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T00:41:31.582087Z",
     "iopub.status.busy": "2025-12-15T00:41:31.581763Z",
     "iopub.status.idle": "2025-12-15T00:41:33.245299Z",
     "shell.execute_reply": "2025-12-15T00:41:33.244254Z"
    }
   },
   "source": [
    "---\n",
    "title: \"Part 2: LLM\"\n",
    "author: \"Group 05\"\n",
    "bibliography: references.bib\n",
    "    hide_input: true\n",
    "exports:\n",
    "  - format: pdf\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d2ad808-11fa-4571-b4ff-350dfe1e7f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce1447ab-6bb3-4e6c-b52d-1fb4aec8f3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "EO = pd.read_csv(\"executive_orders.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01705b71-72d9-40f3-ad52-86187360c8da",
   "metadata": {},
   "source": [
    "## Intro\n",
    "Here, we will fine-tune a small pretrained language model on historical executive order titles to examine whether domain-specific stylistic patterns could be learned. We will compare generated outputs before and after fine-tuning. This experiment is exploratory and qualitative in nature.\n",
    "\n",
    "This notebook explores whether a small pretrained language model can adapt to the stylistic structure of U.S. executive order titles after lightweight fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f23378c4-ed12-48ce-a7f5-699faaf46cb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T00:41:33.280194Z",
     "iopub.status.busy": "2025-12-15T00:41:33.279989Z",
     "iopub.status.idle": "2025-12-15T00:41:33.284209Z",
     "shell.execute_reply": "2025-12-15T00:41:33.283234Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 13)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EO.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c25055-47ff-4bb2-8e03-657f937ccbe1",
   "metadata": {},
   "source": [
    "## Check 'title' column (NA values, type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c2ac99e-0d5c-4ec8-8b31-b9675673ce01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T00:41:33.286636Z",
     "iopub.status.busy": "2025-12-15T00:41:33.286419Z",
     "iopub.status.idle": "2025-12-15T00:41:33.291268Z",
     "shell.execute_reply": "2025-12-15T00:41:33.290337Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if they are all string type\n",
    "EO[\"title\"].dtype == object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fde06f42-3965-4468-8feb-c74fbb894dca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T00:41:33.293443Z",
     "iopub.status.busy": "2025-12-15T00:41:33.293229Z",
     "iopub.status.idle": "2025-12-15T00:41:33.298110Z",
     "shell.execute_reply": "2025-12-15T00:41:33.296968Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#no missing values\n",
    "EO[\"title\"].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6c9841-a001-47e2-afa2-92ff3b35b69f",
   "metadata": {},
   "source": [
    "We verified that the title column contains no missing values and is stored as a string-type variable. This ensures that all executive order titles are valid textual inputs for downstream language-model fine-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f80c5f-6bff-485e-993d-d89b4c67e536",
   "metadata": {},
   "source": [
    "## Check suitability for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ecd8af1-bccf-44ae-a207-0a7dda2def21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T00:41:33.300900Z",
     "iopub.status.busy": "2025-12-15T00:41:33.300626Z",
     "iopub.status.idle": "2025-12-15T00:41:33.305535Z",
     "shell.execute_reply": "2025-12-15T00:41:33.304763Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles_df = EO[\"title\"].reset_index(drop=True).to_frame(name=\"title\")\n",
    "len(titles_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a617e3e7-0229-4aef-ab58-5f5e2a10d8e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T00:41:33.307897Z",
     "iopub.status.busy": "2025-12-15T00:41:33.307668Z",
     "iopub.status.idle": "2025-12-15T00:41:33.317274Z",
     "shell.execute_reply": "2025-12-15T00:41:33.316171Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1000.000000\n",
       "mean       78.167000\n",
       "std        48.402147\n",
       "min        16.000000\n",
       "25%        49.000000\n",
       "50%        66.000000\n",
       "75%        96.000000\n",
       "max       905.000000\n",
       "Name: char_len, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles_df[\"char_len\"] = titles_df[\"title\"].str.len()\n",
    "titles_df[\"char_len\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69d85791-bb46-4660-9095-4d68af1d731d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T00:41:33.319949Z",
     "iopub.status.busy": "2025-12-15T00:41:33.319699Z",
     "iopub.status.idle": "2025-12-15T00:41:33.324348Z",
     "shell.execute_reply": "2025-12-15T00:41:33.323542Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.986"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(titles_df[\"char_len\"]<200)/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3a1f7ff-dbec-49ee-9e94-754e7e70e254",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df_trunc = titles_df[titles_df[\"char_len\"]<200]['title']\n",
    "titles_df_trunc = titles_df_trunc.to_frame(name='title')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e27e247-cf1f-4d68-affb-b66fae5a03a2",
   "metadata": {},
   "source": [
    "Executive order titles are generally short, with a median length of 66 characters, making them well suited for lightweight language-model fine-tuning. Thus, we are going to work with titles with length smaller than 200 for the sake of simplicity of the model, and it covers more than 95% of the total data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45234556-71e0-4d9f-8309-b7d04aed25c1",
   "metadata": {},
   "source": [
    "## Using LLM "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7925d086-1e5b-4122-8898-00b4e90108ed",
   "metadata": {},
   "source": [
    "### Before Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b931456-9041-4df6-945b-914f245de2c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T00:41:33.338070Z",
     "iopub.status.busy": "2025-12-15T00:41:33.337864Z",
     "iopub.status.idle": "2025-12-15T00:41:39.254680Z",
     "shell.execute_reply": "2025-12-15T00:41:39.253641Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/share/envs/finalproj/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23d31d0b-e2b6-44ed-8daa-1aafb9917f98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T00:41:39.257543Z",
     "iopub.status.busy": "2025-12-15T00:41:39.257121Z",
     "iopub.status.idle": "2025-12-15T00:41:40.232312Z",
     "shell.execute_reply": "2025-12-15T00:41:40.231155Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"distilgpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model_base = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "model_base.eval()\n",
    "\n",
    "set_seed(259)  # reproducibility\n",
    "def generate_text(model, prompt, max_new_tokens=20):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        out = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,\n",
    "            temperature=0.8,\n",
    "            top_p=0.95,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    text = tokenizer.decode(out[0], skip_special_tokens=True)\n",
    "    return text.replace(\"\\n\", \" \").strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d192fc62-7124-471c-bdc3-f6ce2ea67f54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T00:41:40.235348Z",
     "iopub.status.busy": "2025-12-15T00:41:40.235044Z",
     "iopub.status.idle": "2025-12-15T00:41:42.309318Z",
     "shell.execute_reply": "2025-12-15T00:41:42.308134Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Executive Order on ix-8-9.',\n",
       " 'Executive Order on Protecting -------------------------',\n",
       " 'Establishing the vernacular is a process that allows us to incorporate the same set of concepts, values, concepts,',\n",
       " 'Amending Executive Order _____',\n",
       " 'Executive Order on National Security and Â Trade in Information.”']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"Executive Order on \",\n",
    "    \"Executive Order on Protecting \",\n",
    "    \"Establishing the \",\n",
    "    \"Amending Executive Order \",\n",
    "    \"Executive Order on National Security and \"\n",
    "]\n",
    "\n",
    "before = []\n",
    "for p in prompts:\n",
    "    before.append(generate_text(model_base, p))\n",
    "before\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e967ee16-0c63-405b-97f3-35889c5b0265",
   "metadata": {},
   "source": [
    "Before fine-tuning, the model often follows the prompt structure but produces placeholders, encoding artifacts, and generic prose, indicating that it has not learned the formal conventions of executive order titles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b2f474-355f-48e4-af3e-6d47f854a046",
   "metadata": {},
   "source": [
    "### After training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29003ecc-d0fa-4a1d-b463-9a73a60da7c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T00:41:42.312075Z",
     "iopub.status.busy": "2025-12-15T00:41:42.311772Z",
     "iopub.status.idle": "2025-12-15T00:41:43.660692Z",
     "shell.execute_reply": "2025-12-15T00:41:43.659658Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   0%|                                                                             | 0/986 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|████████████████████████████████████████████████████████████████| 986/986 [00:00<00:00, 20106.88 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map:   0%|                                                                             | 0/986 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Map: 100%|████████████████████████████████████████████████████████████████| 986/986 [00:00<00:00, 11980.98 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "ds = Dataset.from_dict({\n",
    "    \"text\": titles_df_trunc[\"title\"].tolist()\n",
    "})\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=64\n",
    "    )\n",
    "\n",
    "tokenized = ds.map(tokenize, batched=True, remove_columns=[\"text\"])\n",
    "tokenized = tokenized.map(lambda x: {\"labels\": x[\"input_ids\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5613664-2e10-42a2-b160-01ecc38de394",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T00:41:43.663071Z",
     "iopub.status.busy": "2025-12-15T00:41:43.662814Z",
     "iopub.status.idle": "2025-12-15T00:44:37.405392Z",
     "shell.execute_reply": "2025-12-15T00:44:37.404568Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/share/envs/finalproj/lib/python3.11/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='124' max='124' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [124/124 02:51, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.918400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.544500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=124, training_loss=3.6490478515625, metrics={'train_runtime': 173.2276, 'train_samples_per_second': 5.692, 'train_steps_per_second': 0.716, 'total_flos': 16102412255232.0, 'train_loss': 3.6490478515625, 'epoch': 1.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"llm_ckpt\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=8,\n",
    "    logging_steps=50,\n",
    "    save_steps=200,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "model_ft = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_ft,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3a65553-5ccc-4219-9d66-7931fe9115c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T00:44:37.408070Z",
     "iopub.status.busy": "2025-12-15T00:44:37.407859Z",
     "iopub.status.idle": "2025-12-15T00:44:39.436495Z",
     "shell.execute_reply": "2025-12-15T00:44:39.435432Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Executive Order on ixenable Employment, Economic Performance and Support for the American Indian and Central American Indian Communities, and',\n",
       " 'Executive Order on Protecting ills and Jobs From Terrorist, Terrorist, and Terrorist Extremism Through Government-owned and',\n",
       " 'Establishing the étente Agreement on Civil Rights and Equal Opportunity and Equality in the United States, and Supporting the Initiative',\n",
       " 'Amending Executive Order _____ of 2018 to Prohibit Executive Order No. 13981, Effective on September 13, 2018',\n",
       " 'Executive Order on National Security and ills of the White House Council on the Foreign Relations, Export, and International Organizations, and Export-']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ft.eval()\n",
    "set_seed(259)\n",
    "\n",
    "after = []\n",
    "for p in prompts:\n",
    "    after.append(generate_text(model_ft, p))\n",
    "after\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3cf90b01-413c-4d70-8cf5-eee327338bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============  1th prompt: \"Executive Order on \"  ==============\n",
      "\n",
      "before-tuning: Executive Order on ix-8-9.\n",
      "\n",
      "after-tuning: Executive Order on ixenable Employment, Economic Performance and Support for the American Indian and Central American Indian Communities, and\n",
      "\n",
      "=============  2th prompt: \"Executive Order on Protecting \"  ==============\n",
      "\n",
      "before-tuning: Executive Order on Protecting -------------------------\n",
      "\n",
      "after-tuning: Executive Order on Protecting ills and Jobs From Terrorist, Terrorist, and Terrorist Extremism Through Government-owned and\n",
      "\n",
      "=============  3th prompt: \"Establishing the \"  ==============\n",
      "\n",
      "before-tuning: Establishing the vernacular is a process that allows us to incorporate the same set of concepts, values, concepts,\n",
      "\n",
      "after-tuning: Establishing the étente Agreement on Civil Rights and Equal Opportunity and Equality in the United States, and Supporting the Initiative\n",
      "\n",
      "=============  4th prompt: \"Amending Executive Order \"  ==============\n",
      "\n",
      "before-tuning: Amending Executive Order _____\n",
      "\n",
      "after-tuning: Amending Executive Order _____ of 2018 to Prohibit Executive Order No. 13981, Effective on September 13, 2018\n",
      "\n",
      "=============  5th prompt: \"Executive Order on National Security and \"  ==============\n",
      "\n",
      "before-tuning: Executive Order on National Security and Â Trade in Information.”\n",
      "\n",
      "after-tuning: Executive Order on National Security and ills of the White House Council on the Foreign Relations, Export, and International Organizations, and Export-\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame({\n",
    "    \"prompt\": prompts,\n",
    "    \"before\": before,\n",
    "    \"after\": after\n",
    "})\n",
    "results.to_csv(\"outputs/llm_title_outputs.csv\", index=False)\n",
    "\n",
    "for i, row in results.iterrows():\n",
    "    print(f\"=============  {i+1}th prompt: \\\"{row['prompt']}\\\"  ==============\\n\")\n",
    "    print(f\"before-tuning: {row['before']}\\n\")\n",
    "    print(f\"after-tuning: {row['after']}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f9e313-18e4-4baa-b840-431ac6c40467",
   "metadata": {},
   "source": [
    "After one epoch of fine-tuning on historical executive order titles, the model’s generations become noticeably more aligned with the formal structure of real EO titles. In particular, the fine-tuned outputs more frequently include administrative phrasing (e.g., “Establishing…”, “Amending Executive Order…”, references to EO numbers, and effective dates) that was largely absent or inconsistent in baseline generations. While some artifacts remain (occasional repetition and nonsensical fragments), the overall tone and format shift toward the bureaucratic, title-like style of the training corpus. This suggests that even lightweight fine-tuning can adapt a small pretrained language model to domain-specific writing conventions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPython - finalproj",
   "language": "python",
   "name": "finalproj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
